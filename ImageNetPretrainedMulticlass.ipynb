{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageNetPretrainedMulticlass.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNraW9Yb5p5zTxmozkl2pm2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tylerb55/COMP530/blob/main/ImageNetPretrainedMulticlass.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsGFBvoCm86V",
        "outputId": "bf4e4322-12a2-4fde-dd20-7aae76012073",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'COMP530'...\n",
            "remote: Enumerating objects: 4276, done.\u001b[K\n",
            "remote: Counting objects: 100% (60/60), done.\u001b[K\n",
            "remote: Compressing objects: 100% (60/60), done.\u001b[K\n",
            "remote: Total 4276 (delta 33), reused 0 (delta 0), pack-reused 4216\u001b[K\n",
            "Receiving objects: 100% (4276/4276), 917.13 MiB | 16.29 MiB/s, done.\n",
            "Resolving deltas: 100% (114/114), done.\n",
            "Checking out files: 100% (1162/1162), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/tylerb55/COMP530.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import collections\n",
        "import matplotlib.image as img\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import PIL.Image as Image"
      ],
      "metadata": {
        "id": "gXLBlMwpnK7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Split the train test and validation set**"
      ],
      "metadata": {
        "id": "tFQN5RyMow-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Train_Validation_Test_Set(directory_name):\n",
        "  \"\"\"a function to load the images in a large directory into a tensorflow dataset object\n",
        "  the data is split 80:10:10 in training:validation:test. The dataset is shuffled before splitting\n",
        "  and the images are formatted to 512x512 pixels (pixel values range from 0 to 255)\n",
        "  Images are labelled 0,1 based on the folder they are in. Normalcases are 0 and \n",
        "  cancercases are 1\"\"\"\n",
        "  dataset_train=tf.keras.preprocessing.image_dataset_from_directory('/content/COMP530/'+directory_name,\n",
        "                                                                    labels='inferred',\n",
        "                                                                    label_mode='int',\n",
        "                                                                    class_names=['type a','type b','type e','type g'],\n",
        "                                                                    image_size=(512,512),\n",
        "                                                                    shuffle=True,\n",
        "                                                                    seed=305,\n",
        "                                                                    validation_split=0.2,\n",
        "                                                                    subset='training',\n",
        "                                                                    batch_size=None\n",
        "                                                                    )\n",
        "\n",
        "  dataset_validation=tf.keras.preprocessing.image_dataset_from_directory('/content/COMP530/'+directory_name,\n",
        "                                                                    labels='inferred',\n",
        "                                                                    label_mode='int',\n",
        "                                                                    class_names=['type a','type b','type e','type g'],\n",
        "                                                                    image_size=(512,512),\n",
        "                                                                    shuffle=True,\n",
        "                                                                    seed=305,\n",
        "                                                                    validation_split=0.2,\n",
        "                                                                    subset='validation',\n",
        "                                                                    batch_size=None\n",
        "                                                                    )\n",
        "  \n",
        "  dataset_test=tf.keras.preprocessing.image_dataset_from_directory('/content/COMP530/'+directory_name,\n",
        "                                                                    labels='inferred',\n",
        "                                                                    label_mode='int',\n",
        "                                                                    class_names=['type a','type b','type e','type g'],\n",
        "                                                                    image_size=(512,512),\n",
        "                                                                    shuffle=True,\n",
        "                                                                    seed=305,\n",
        "                                                                    validation_split=0.1,\n",
        "                                                                    subset='validation',\n",
        "                                                                    batch_size=None\n",
        "                                                                    )\n",
        "    \n",
        "  dataset_validation=dataset_validation.take(dataset_test.__len__())\n",
        "\n",
        "  return dataset_train,dataset_validation,dataset_test"
      ],
      "metadata": {
        "id": "0xqnACYcnK92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Preprocess(image,label):\n",
        "  image = image/255.0\n",
        "  # Resize images from 512x512 to 224x224\n",
        "  image = tf.image.resize(image, (224,224))\n",
        "  return image, label"
      ],
      "metadata": {
        "id": "SSTkz2KVnLAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE=32\n",
        "\n",
        "dataset_train,dataset_validation, dataset_test=Train_Validation_Test_Set(\"Dataset2\")\n",
        "dataset_train=dataset_train.map(Preprocess).batch(batch_size=BATCH_SIZE,drop_remainder=True)\n",
        "dataset_validation=dataset_validation.map(Preprocess).batch(batch_size=BATCH_SIZE,drop_remainder=True)\n",
        "dataset_test=dataset_test.map(Preprocess).batch(batch_size=BATCH_SIZE,drop_remainder=True)\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "dataset_train = dataset_train.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "dataset_validation = dataset_validation.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "sasC3SMInLDm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f677530-e380-4a60-c437-c2a44e053ab9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1097 files belonging to 2 classes.\n",
            "Using 878 files for training.\n",
            "Found 1097 files belonging to 2 classes.\n",
            "Using 219 files for validation.\n",
            "Found 1097 files belonging to 2 classes.\n",
            "Using 109 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MobileNetV2**"
      ],
      "metadata": {
        "id": "DIIXlp_N6oY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model=tf.keras.applications.MobileNetV2(weights='imagenet',input_shape=(224,224,3),include_top=False) # use mobilenetv2 as the base for the tl model\n",
        "base_model.trainable = False # freeze the mobilenetv2 layers\n",
        "\n",
        "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "# We make sure that the base_model is running in inference mode here,\n",
        "# by passing `training=False`.\n",
        "x = base_model(inputs, training=True)\n",
        "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
        "#x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dense(128,activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "# A Dense classifier with a 4 unit (categorical classification)\n",
        "outputs = tf.keras.layers.Dense(4,activation='softmax')(x)\n",
        "mobilenet = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "mobilenet.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8uDHmpND7u5",
        "outputId": "2336cc73-4d7d-44d4-c13e-eb310a3b5452"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " global_average_pooling2d_1   (None, 1280)             0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1280)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 1281      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,259,265\n",
            "Trainable params: 1,281\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mobilenet.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(),\n",
        "  loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "  metrics=[tf.keras.metrics.BinaryAccuracy(),tf.keras.metrics.TruePositives(),tf.keras.metrics.FalsePositives(),tf.keras.metrics.TrueNegatives(),tf.keras.metrics.FalseNegatives()])\n",
        "\n",
        "NUM_EPOCHS = 30\n",
        "\n",
        "history = mobilenet.fit(dataset_train,\n",
        "                    validation_data=dataset_validation,\n",
        "                    epochs=NUM_EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "Nayf5sJpGXpJ",
        "outputId": "5eeb70b7-795f-40ee-afd3-47141a912029"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "27/27 [==============================] - 26s 837ms/step - loss: 0.5812 - binary_accuracy: 0.6852 - true_positives_1: 428.0000 - false_positives_1: 163.0000 - true_negatives_1: 164.0000 - false_negatives_1: 109.0000\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 22s 828ms/step - loss: 0.3631 - binary_accuracy: 0.8414 - true_positives_1: 473.0000 - false_positives_1: 73.0000 - true_negatives_1: 254.0000 - false_negatives_1: 64.0000\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 22s 830ms/step - loss: 0.3306 - binary_accuracy: 0.8576 - true_positives_1: 470.0000 - false_positives_1: 56.0000 - true_negatives_1: 271.0000 - false_negatives_1: 67.0000\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 22s 831ms/step - loss: 0.3092 - binary_accuracy: 0.8762 - true_positives_1: 476.0000 - false_positives_1: 46.0000 - true_negatives_1: 281.0000 - false_negatives_1: 61.0000\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 22s 832ms/step - loss: 0.2739 - binary_accuracy: 0.8808 - true_positives_1: 476.0000 - false_positives_1: 42.0000 - true_negatives_1: 285.0000 - false_negatives_1: 61.0000\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 22s 830ms/step - loss: 0.2729 - binary_accuracy: 0.8831 - true_positives_1: 478.0000 - false_positives_1: 42.0000 - true_negatives_1: 285.0000 - false_negatives_1: 59.0000\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 22s 831ms/step - loss: 0.2452 - binary_accuracy: 0.8912 - true_positives_1: 477.0000 - false_positives_1: 34.0000 - true_negatives_1: 293.0000 - false_negatives_1: 60.0000\n",
            "Epoch 8/30\n",
            " 5/27 [====>.........................] - ETA: 18s - loss: 0.2693 - binary_accuracy: 0.8938 - true_positives_1: 83.0000 - false_positives_1: 6.0000 - true_negatives_1: 60.0000 - false_negatives_1: 11.0000"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-d7cec99e1bc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m history = mobilenet.fit(dataset_train,\n\u001b[1;32m      9\u001b[0m                     \u001b[0;31m#validation_data=dataset_validation,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                     epochs=NUM_EPOCHS)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history.history['binary_accuracy'])\n",
        "plt.plot(history.history['val_binary_accuracy'])\n",
        "plt.title('training accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('training loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "wznzxN5RLaQo",
        "outputId": "28610332-9aa7-4073-f913-c66578cd69c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-d52d6319a46a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# summarize history for accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'acc'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ResNet50**"
      ],
      "metadata": {
        "id": "Ducc8ja36SJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model=tf.keras.applications.ResNet50(weights='imagenet',input_shape=(224,224,3),include_top=False) # use resnet50 as the base for the tl model\n",
        "base_model.trainable = False # freeze the resnet50 layers\n",
        "\n",
        "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "# We make sure that the base_model is running in inference mode here,\n",
        "# by passing `training=False`.\n",
        "x = base_model(inputs, training=True)\n",
        "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
        "#x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dense(128,activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "# A Dense classifier with a 4 unit (categorical classification)\n",
        "outputs = tf.keras.layers.Dense(4,activation='softmax')(x)\n",
        "resnet = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "resnet.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxJ7eTCz3wbW",
        "outputId": "882e24d2-fcc1-4eda-dcc6-9751c3012dd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " keras_layer_3 (KerasLayer)  (None, 2048)              23561152  \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 2049      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,563,201\n",
            "Trainable params: 2,049\n",
            "Non-trainable params: 23,561,152\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(),\n",
        "  loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "  metrics=[tf.keras.metrics.BinaryAccuracy(),tf.keras.metrics.TruePositives(),tf.keras.metrics.FalsePositives(),tf.keras.metrics.TrueNegatives(),tf.keras.metrics.FalseNegatives()])\n",
        "\n",
        "NUM_EPOCHS = 30\n",
        "\n",
        "history = resnet.fit(dataset_train,\n",
        "                    validation_data=dataset_validation,\n",
        "                    epochs=NUM_EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tav2GYVI5lZ_",
        "outputId": "13fef03c-dfdd-4222-b83d-e0dd57d68665"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "27/27 [==============================] - 9s 105ms/step - loss: 0.4551 - binary_accuracy: 0.7650 - precision_1: 0.8047 - val_loss: 0.4348 - val_binary_accuracy: 0.8333 - val_precision_1: 0.8387\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 2s 68ms/step - loss: 0.3064 - binary_accuracy: 0.8773 - precision_1: 0.9168 - val_loss: 0.3896 - val_binary_accuracy: 0.8542 - val_precision_1: 0.8667\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 2s 66ms/step - loss: 0.2700 - binary_accuracy: 0.8900 - precision_1: 0.9438 - val_loss: 0.3471 - val_binary_accuracy: 0.8333 - val_precision_1: 0.8621\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 2s 66ms/step - loss: 0.2452 - binary_accuracy: 0.8981 - precision_1: 0.9517 - val_loss: 0.3243 - val_binary_accuracy: 0.8542 - val_precision_1: 0.8793\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 2s 66ms/step - loss: 0.2264 - binary_accuracy: 0.8970 - precision_1: 0.9534 - val_loss: 0.3080 - val_binary_accuracy: 0.8542 - val_precision_1: 0.8793\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 2s 67ms/step - loss: 0.2107 - binary_accuracy: 0.9097 - precision_1: 0.9636 - val_loss: 0.2946 - val_binary_accuracy: 0.8542 - val_precision_1: 0.8793\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 2s 73ms/step - loss: 0.1973 - binary_accuracy: 0.9132 - precision_1: 0.9657 - val_loss: 0.2834 - val_binary_accuracy: 0.8542 - val_precision_1: 0.8793\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 2s 69ms/step - loss: 0.1857 - binary_accuracy: 0.9259 - precision_1: 0.9721 - val_loss: 0.2738 - val_binary_accuracy: 0.8646 - val_precision_1: 0.8814\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 2s 66ms/step - loss: 0.1755 - binary_accuracy: 0.9375 - precision_1: 0.9726 - val_loss: 0.2653 - val_binary_accuracy: 0.8750 - val_precision_1: 0.8966\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 2s 66ms/step - loss: 0.1663 - binary_accuracy: 0.9444 - precision_1: 0.9766 - val_loss: 0.2578 - val_binary_accuracy: 0.8750 - val_precision_1: 0.8966\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history.history['binary_accuracy'])\n",
        "plt.plot(history.history['val_binary_accuracy'])\n",
        "plt.title('training accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('training loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6SyGrKsl7cBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DenseNet121**"
      ],
      "metadata": {
        "id": "raw-Axvqbos0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model=tf.keras.applications.DenseNet121(weights='imagenet',input_shape=(224,224,3),include_top=False) # use densenet121 as the base for the tl model\n",
        "base_model.trainable = False # freeze the densenet121 layers\n",
        "\n",
        "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "# We make sure that the base_model is running in inference mode here,\n",
        "# by passing `training=False`.\n",
        "x = base_model(inputs, training=True)\n",
        "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
        "#x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dense(128,activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "# A Dense classifier with a 4 unit (categorical classification)\n",
        "outputs = tf.keras.layers.Dense(4,activation='softmax')(x)\n",
        "densenet = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "densenet.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "882e24d2-fcc1-4eda-dcc6-9751c3012dd7",
        "id": "8a-W7gjUbotD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " keras_layer_3 (KerasLayer)  (None, 2048)              23561152  \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 2049      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,563,201\n",
            "Trainable params: 2,049\n",
            "Non-trainable params: 23,561,152\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "densenet.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(),\n",
        "  loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "  metrics=[tf.keras.metrics.BinaryAccuracy(),tf.keras.metrics.TruePositives(),tf.keras.metrics.FalsePositives(),tf.keras.metrics.TrueNegatives(),tf.keras.metrics.FalseNegatives()])\n",
        "\n",
        "NUM_EPOCHS = 30\n",
        "\n",
        "history = densenet.fit(dataset_train,\n",
        "                    validation_data=dataset_validation,\n",
        "                    epochs=NUM_EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13fef03c-dfdd-4222-b83d-e0dd57d68665",
        "id": "wWwyULVJbotF"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "27/27 [==============================] - 9s 105ms/step - loss: 0.4551 - binary_accuracy: 0.7650 - precision_1: 0.8047 - val_loss: 0.4348 - val_binary_accuracy: 0.8333 - val_precision_1: 0.8387\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 2s 68ms/step - loss: 0.3064 - binary_accuracy: 0.8773 - precision_1: 0.9168 - val_loss: 0.3896 - val_binary_accuracy: 0.8542 - val_precision_1: 0.8667\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 2s 66ms/step - loss: 0.2700 - binary_accuracy: 0.8900 - precision_1: 0.9438 - val_loss: 0.3471 - val_binary_accuracy: 0.8333 - val_precision_1: 0.8621\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 2s 66ms/step - loss: 0.2452 - binary_accuracy: 0.8981 - precision_1: 0.9517 - val_loss: 0.3243 - val_binary_accuracy: 0.8542 - val_precision_1: 0.8793\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 2s 66ms/step - loss: 0.2264 - binary_accuracy: 0.8970 - precision_1: 0.9534 - val_loss: 0.3080 - val_binary_accuracy: 0.8542 - val_precision_1: 0.8793\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 2s 67ms/step - loss: 0.2107 - binary_accuracy: 0.9097 - precision_1: 0.9636 - val_loss: 0.2946 - val_binary_accuracy: 0.8542 - val_precision_1: 0.8793\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 2s 73ms/step - loss: 0.1973 - binary_accuracy: 0.9132 - precision_1: 0.9657 - val_loss: 0.2834 - val_binary_accuracy: 0.8542 - val_precision_1: 0.8793\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 2s 69ms/step - loss: 0.1857 - binary_accuracy: 0.9259 - precision_1: 0.9721 - val_loss: 0.2738 - val_binary_accuracy: 0.8646 - val_precision_1: 0.8814\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 2s 66ms/step - loss: 0.1755 - binary_accuracy: 0.9375 - precision_1: 0.9726 - val_loss: 0.2653 - val_binary_accuracy: 0.8750 - val_precision_1: 0.8966\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 2s 66ms/step - loss: 0.1663 - binary_accuracy: 0.9444 - precision_1: 0.9766 - val_loss: 0.2578 - val_binary_accuracy: 0.8750 - val_precision_1: 0.8966\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history.history['binary_accuracy'])\n",
        "plt.plot(history.history['val_binary_accuracy'])\n",
        "plt.title('training accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('training loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EZyqF18nbotG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **VGG16**"
      ],
      "metadata": {
        "id": "xpv8CUvgcUvw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model=tf.keras.applications.VGG16(weights='imagenet',input_shape=(224,224,3),include_top=False) # use vgg16 as the base for the tl model\n",
        "base_model.trainable = False # freeze the vgg16 layers\n",
        "\n",
        "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "# We make sure that the base_model is running in inference mode here,\n",
        "# by passing `training=False`.\n",
        "x = base_model(inputs, training=True)\n",
        "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
        "#x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dense(128,activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "# A Dense classifier with a 4 unit (categorical classification)\n",
        "outputs = tf.keras.layers.Dense(4,activation='softmax')(x)\n",
        "vgg = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "vgg.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "882e24d2-fcc1-4eda-dcc6-9751c3012dd7",
        "id": "3U_tCYvkcUv8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " keras_layer_3 (KerasLayer)  (None, 2048)              23561152  \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 2049      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,563,201\n",
            "Trainable params: 2,049\n",
            "Non-trainable params: 23,561,152\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(),\n",
        "  loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "  metrics=[tf.keras.metrics.BinaryAccuracy(),tf.keras.metrics.TruePositives(),tf.keras.metrics.FalsePositives(),tf.keras.metrics.TrueNegatives(),tf.keras.metrics.FalseNegatives()])\n",
        "\n",
        "NUM_EPOCHS = 30\n",
        "\n",
        "history = vgg.fit(dataset_train,\n",
        "                    validation_data=dataset_validation,\n",
        "                    epochs=NUM_EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13fef03c-dfdd-4222-b83d-e0dd57d68665",
        "id": "inLAHPAtcUv-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "27/27 [==============================] - 9s 105ms/step - loss: 0.4551 - binary_accuracy: 0.7650 - precision_1: 0.8047 - val_loss: 0.4348 - val_binary_accuracy: 0.8333 - val_precision_1: 0.8387\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 2s 68ms/step - loss: 0.3064 - binary_accuracy: 0.8773 - precision_1: 0.9168 - val_loss: 0.3896 - val_binary_accuracy: 0.8542 - val_precision_1: 0.8667\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 2s 66ms/step - loss: 0.2700 - binary_accuracy: 0.8900 - precision_1: 0.9438 - val_loss: 0.3471 - val_binary_accuracy: 0.8333 - val_precision_1: 0.8621\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 2s 66ms/step - loss: 0.2452 - binary_accuracy: 0.8981 - precision_1: 0.9517 - val_loss: 0.3243 - val_binary_accuracy: 0.8542 - val_precision_1: 0.8793\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 2s 66ms/step - loss: 0.2264 - binary_accuracy: 0.8970 - precision_1: 0.9534 - val_loss: 0.3080 - val_binary_accuracy: 0.8542 - val_precision_1: 0.8793\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 2s 67ms/step - loss: 0.2107 - binary_accuracy: 0.9097 - precision_1: 0.9636 - val_loss: 0.2946 - val_binary_accuracy: 0.8542 - val_precision_1: 0.8793\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 2s 73ms/step - loss: 0.1973 - binary_accuracy: 0.9132 - precision_1: 0.9657 - val_loss: 0.2834 - val_binary_accuracy: 0.8542 - val_precision_1: 0.8793\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 2s 69ms/step - loss: 0.1857 - binary_accuracy: 0.9259 - precision_1: 0.9721 - val_loss: 0.2738 - val_binary_accuracy: 0.8646 - val_precision_1: 0.8814\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 2s 66ms/step - loss: 0.1755 - binary_accuracy: 0.9375 - precision_1: 0.9726 - val_loss: 0.2653 - val_binary_accuracy: 0.8750 - val_precision_1: 0.8966\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 2s 66ms/step - loss: 0.1663 - binary_accuracy: 0.9444 - precision_1: 0.9766 - val_loss: 0.2578 - val_binary_accuracy: 0.8750 - val_precision_1: 0.8966\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history.history['binary_accuracy'])\n",
        "plt.plot(history.history['val_binary_accuracy'])\n",
        "plt.title('training accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('training loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oZ6ZCbrRcUv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **InceptionV3**"
      ],
      "metadata": {
        "id": "nFX3mtocc43C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model=tf.keras.applications.InceptionV3(weights='imagenet',input_shape=(224,224,3),include_top=False) # use inceptionv3 as the base for the tl model\n",
        "base_model.trainable = False # freeze the inceptionv3 layers\n",
        "\n",
        "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "# We make sure that the base_model is running in inference mode here,\n",
        "# by passing `training=False`.\n",
        "x = base_model(inputs, training=True)\n",
        "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
        "#x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dense(128,activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "# A Dense classifier with a 4 unit (categorical classification)\n",
        "outputs = tf.keras.layers.Dense(4,activation='softmax')(x)\n",
        "inception = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "inception.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "882e24d2-fcc1-4eda-dcc6-9751c3012dd7",
        "id": "sevprnu3c43Q"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " keras_layer_3 (KerasLayer)  (None, 2048)              23561152  \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 2049      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,563,201\n",
            "Trainable params: 2,049\n",
            "Non-trainable params: 23,561,152\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inception.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(),\n",
        "  loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "  metrics=[tf.keras.metrics.BinaryAccuracy(),tf.keras.metrics.TruePositives(),tf.keras.metrics.FalsePositives(),tf.keras.metrics.TrueNegatives(),tf.keras.metrics.FalseNegatives()])\n",
        "\n",
        "NUM_EPOCHS = 30\n",
        "\n",
        "history = inception.fit(dataset_train,\n",
        "                    validation_data=dataset_validation,\n",
        "                    epochs=NUM_EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13fef03c-dfdd-4222-b83d-e0dd57d68665",
        "id": "9xJvlNlBc43S"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "27/27 [==============================] - 9s 105ms/step - loss: 0.4551 - binary_accuracy: 0.7650 - precision_1: 0.8047 - val_loss: 0.4348 - val_binary_accuracy: 0.8333 - val_precision_1: 0.8387\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 2s 68ms/step - loss: 0.3064 - binary_accuracy: 0.8773 - precision_1: 0.9168 - val_loss: 0.3896 - val_binary_accuracy: 0.8542 - val_precision_1: 0.8667\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 2s 66ms/step - loss: 0.2700 - binary_accuracy: 0.8900 - precision_1: 0.9438 - val_loss: 0.3471 - val_binary_accuracy: 0.8333 - val_precision_1: 0.8621\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 2s 66ms/step - loss: 0.2452 - binary_accuracy: 0.8981 - precision_1: 0.9517 - val_loss: 0.3243 - val_binary_accuracy: 0.8542 - val_precision_1: 0.8793\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 2s 66ms/step - loss: 0.2264 - binary_accuracy: 0.8970 - precision_1: 0.9534 - val_loss: 0.3080 - val_binary_accuracy: 0.8542 - val_precision_1: 0.8793\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 2s 67ms/step - loss: 0.2107 - binary_accuracy: 0.9097 - precision_1: 0.9636 - val_loss: 0.2946 - val_binary_accuracy: 0.8542 - val_precision_1: 0.8793\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 2s 73ms/step - loss: 0.1973 - binary_accuracy: 0.9132 - precision_1: 0.9657 - val_loss: 0.2834 - val_binary_accuracy: 0.8542 - val_precision_1: 0.8793\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 2s 69ms/step - loss: 0.1857 - binary_accuracy: 0.9259 - precision_1: 0.9721 - val_loss: 0.2738 - val_binary_accuracy: 0.8646 - val_precision_1: 0.8814\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 2s 66ms/step - loss: 0.1755 - binary_accuracy: 0.9375 - precision_1: 0.9726 - val_loss: 0.2653 - val_binary_accuracy: 0.8750 - val_precision_1: 0.8966\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 2s 66ms/step - loss: 0.1663 - binary_accuracy: 0.9444 - precision_1: 0.9766 - val_loss: 0.2578 - val_binary_accuracy: 0.8750 - val_precision_1: 0.8966\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history.history['binary_accuracy'])\n",
        "plt.plot(history.history['val_binary_accuracy'])\n",
        "plt.title('training accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('training loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sXcIv63Cc43S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluation**"
      ],
      "metadata": {
        "id": "fmJYbfTyeeEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mobilenet.evaluate(dataset_test)"
      ],
      "metadata": {
        "id": "0LFqZgM97O_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet.evaluate(dataset_test)"
      ],
      "metadata": {
        "id": "ZUrHIr-3owd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "densenet.evaluate(dataset_test)"
      ],
      "metadata": {
        "id": "h2wXm5KXd2g-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg.evaluate(dataset_test)"
      ],
      "metadata": {
        "id": "XdlSzFL8d3Ft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inception.evaluate(dataset_test)"
      ],
      "metadata": {
        "id": "WntPWChLd3Sd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}