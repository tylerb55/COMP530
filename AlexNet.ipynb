{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlexNet.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMszyn5+mfRy28PFlzaTk0X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tylerb55/COMP530/blob/main/AlexNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nsGFBvoCm86V",
        "outputId": "d3ef476e-5e0f-40f3-860f-2f23c0bb4fec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'COMP530'...\n",
            "remote: Enumerating objects: 1272, done.\u001b[K\n",
            "remote: Counting objects: 100% (346/346), done.\u001b[K\n",
            "remote: Compressing objects: 100% (343/343), done.\u001b[K\n",
            "remote: Total 1272 (delta 47), reused 0 (delta 0), pack-reused 926\u001b[K\n",
            "Receiving objects: 100% (1272/1272), 159.91 MiB | 11.90 MiB/s, done.\n",
            "Resolving deltas: 100% (59/59), done.\n",
            "Checking out files: 100% (1159/1159), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/tylerb55/COMP530.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fast_ml"
      ],
      "metadata": {
        "id": "l6u_8x-tK8r1",
        "outputId": "0db0674b-b954-4457-ddd9-45edf4a069a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fast_ml\n",
            "  Downloading fast_ml-3.68-py3-none-any.whl (42 kB)\n",
            "\u001b[?25l\r\u001b[K     |███████▉                        | 10 kB 16.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 20 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 30 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 40 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 42 kB 440 kB/s \n",
            "\u001b[?25hInstalling collected packages: fast-ml\n",
            "Successfully installed fast-ml-3.68\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import collections\n",
        "import matplotlib.image as img\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from fast_ml.model_development import train_valid_test_split"
      ],
      "metadata": {
        "id": "gXLBlMwpnK7H"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the test and validation set"
      ],
      "metadata": {
        "id": "tFQN5RyMow-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Train_Test_Set(directory_name):\n",
        "  \"\"\"a function to load the images in a large directory into a tensorflow dataset object\n",
        "  the data is split 90:10 in training:validation. The dataset is shuffled before splitting\n",
        "  and the images are formatted to 512x512 pixels and grayscale(one color channel and the values range from 0 to 255)\"\"\"\n",
        "  dataset_train=tf.keras.preprocessing.image_dataset_from_directory('/content/COMP530/'+directory_name,\n",
        "                                                                    labels='inferred',\n",
        "                                                                    label_mode='int',\n",
        "                                                                    class_names=['NormalCases','cancercases'],\n",
        "                                                                    color_mode='grayscale',\n",
        "                                                                    image_size=(512,512),\n",
        "                                                                    shuffle=True,\n",
        "                                                                    seed=305,\n",
        "                                                                    validation_split=0.1,\n",
        "                                                                    subset='training',\n",
        "                                                                    batch_size=None\n",
        "                                                                    )\n",
        "\n",
        "  dataset_test=tf.keras.preprocessing.image_dataset_from_directory('/content/COMP530/'+directory_name,\n",
        "                                                                    labels='inferred',\n",
        "                                                                    label_mode='int',\n",
        "                                                                    class_names=['NormalCases','cancercases'],\n",
        "                                                                    color_mode='grayscale',\n",
        "                                                                    image_size=(512,512),\n",
        "                                                                    shuffle=True,\n",
        "                                                                    seed=305,\n",
        "                                                                    validation_split=0.1,\n",
        "                                                                    subset='validation',\n",
        "                                                                    batch_size=None\n",
        "                                                                    )\n",
        "\n",
        "  return dataset_train,dataset_test"
      ],
      "metadata": {
        "id": "0xqnACYcnK92"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_Dataset(directory_name):\n",
        "  \"\"\"a function to load the images in a large directory into a tensorflow dataset object\n",
        "  The dataset is shuffled and the imagesare formatted to 512x512 pixels and grayscale\n",
        "  (one color channel and the values range from 0 to 255)\"\"\"\n",
        "  dataset_train=tf.keras.preprocessing.image_dataset_from_directory('/content/COMP530/'+directory_name,\n",
        "                                                                    labels='inferred',\n",
        "                                                                    label_mode='int',\n",
        "                                                                    class_names=['NormalCases','cancercases'],\n",
        "                                                                    color_mode='grayscale',\n",
        "                                                                    image_size=(512,512),\n",
        "                                                                    shuffle=True,\n",
        "                                                                    seed=305,\n",
        "                                                                    validation_split=None,\n",
        "                                                                    batch_size=None\n",
        "                                                                    )"
      ],
      "metadata": {
        "id": "sDGtaKlYaD0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_1_train, dataset_1_test=Train_Test_Set(\"Dataset1\")\n",
        "dataset_1_train=dataset_1_train.as_numpy_iterator()\n",
        "df=pd.DataFrame(dataset_1_train,columns=['X','Y'])\n",
        "X_train, y_train, X_valid, y_valid, X_test, y_test=train_valid_test_split(df,target='Y',train_size=0.8,valid_size=0.1,test_size=0.1)"
      ],
      "metadata": {
        "id": "leyEHPSyyT_9",
        "outputId": "881d5430-c757-425e-be20-d34b94de2821",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1097 files belonging to 2 classes.\n",
            "Using 988 files for training.\n",
            "Found 1097 files belonging to 2 classes.\n",
            "Using 109 files for validation.\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def AlexNetPreprocess(image,label):\n",
        "  image = tf.image.per_image_standardization(image)\n",
        "  # Resize images from 512x512 to 227x227\n",
        "  image = tf.image.resize(image, (227,227))\n",
        "  return image, label"
      ],
      "metadata": {
        "id": "SSTkz2KVnLAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset_1_train, dataset_1_test=Train_Test_Set(\"Dataset1\")\n",
        "#dataset_1_train=dataset_1_train.map(AlexNetPreprocess).batch(batch_size=32,drop_remainder=True)\n",
        "#dataset_1_test=dataset_1_test.map(AlexNetPreprocess).batch(batch_size=32,drop_remainder=True)"
      ],
      "metadata": {
        "id": "sasC3SMInLDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def AlexNet_model():\n",
        "   return tf.keras.models.Sequential([\n",
        "                                      tf.keras.layers.Conv2D(filters=96,kernel_size=(11,11),strides=(4,4),activation='relu',input_shape=(227,227,1)),\n",
        "                                      tf.keras.layers.BatchNormalization(),\n",
        "                                      tf.keras.layers.MaxPool2D(pool_size=(3,3),strides=(2,2)),\n",
        "                                      tf.keras.layers.Conv2D(filters=256,kernel_size=(5,5),strides=(1,1),activation='relu',padding='same'),\n",
        "                                      tf.keras.layers.BatchNormalization(),\n",
        "                                      tf.keras.layers.MaxPool2D(pool_size=(3,3),strides=(2,2)),\n",
        "                                      tf.keras.layers.Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same'),\n",
        "                                      tf.keras.layers.BatchNormalization(),\n",
        "                                      tf.keras.layers.Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same'),\n",
        "                                      tf.keras.layers.BatchNormalization(),\n",
        "                                      tf.keras.layers.Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same'),\n",
        "                                      tf.keras.layers.BatchNormalization(),\n",
        "                                      tf.keras.layers.MaxPool2D(pool_size=(3,3),strides=(2,2)),\n",
        "                                      tf.keras.layers.Flatten(),\n",
        "                                      tf.keras.layers.Dense(4096,activation='relu'),\n",
        "                                      tf.keras.layers.Dropout(0.5),\n",
        "                                      tf.keras.layers.Dense(4096,activation='relu'),\n",
        "                                      tf.keras.layers.Dropout(0.5),\n",
        "                                      tf.keras.layers.Dense(10,activation='softmax')\n",
        "])\n",
        "\n",
        "AlexNet = AlexNet_model()"
      ],
      "metadata": {
        "id": "7TwRNVTNoZo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AlexNet.compile(loss='sparse_categorical_crossentropy',optimizer=tf.optimizers.SGD(learning_rate=0.001),metrics=['accuracy'])\n",
        "AlexNet.summary()"
      ],
      "metadata": {
        "id": "R9VwV7croaHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#AlexNet.fit(dataset_1_train,epochs=50,validation_data=dataset_1_test,validation_freq=1)"
      ],
      "metadata": {
        "id": "rQb5G05JoqEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AlexNet.fit(x=X_train.values,y=y_train.values,batch_size=32,epochs=50,validation_data=(X_valid,y_valid),validation_freq=1)"
      ],
      "metadata": {
        "id": "HOOv3Cu2Zton"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the model on the test set and evaluate performance"
      ],
      "metadata": {
        "id": "b-lIum5Bo7SO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZUrHIr-3owd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Produce graphs and visualisations for evalutation data"
      ],
      "metadata": {
        "id": "Rfm_GSa5pD6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ft4xFVzzpEQ2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}