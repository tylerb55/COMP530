{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlexNet.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOj8Ce3xBh7Dnlp1LvBjzFL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tylerb55/COMP530/blob/main/ResNetxMobileNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nsGFBvoCm86V",
        "outputId": "9481cc48-82ec-4ed9-9f39-10763f1b2e5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'COMP530' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/tylerb55/COMP530.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import collections\n",
        "import matplotlib.image as img\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import PIL.Image as Image"
      ],
      "metadata": {
        "id": "gXLBlMwpnK7H"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Split the train test and validation set**"
      ],
      "metadata": {
        "id": "tFQN5RyMow-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Train_Validation_Test_Set(directory_name):\n",
        "  \"\"\"a function to load the images in a large directory into a tensorflow dataset object\n",
        "  the data is split 80:10:10 in training:validation:test. The dataset is shuffled before splitting\n",
        "  and the images are formatted to 512x512 pixels and grayscale(one color channel and the values range from 0 to 255)\"\"\"\n",
        "  dataset_train=tf.keras.preprocessing.image_dataset_from_directory('/content/COMP530/'+directory_name,\n",
        "                                                                    labels='inferred',\n",
        "                                                                    label_mode='int',\n",
        "                                                                    class_names=['NormalCases','cancercases'],\n",
        "                                                                    image_size=(512,512),\n",
        "                                                                    shuffle=True,\n",
        "                                                                    seed=305,\n",
        "                                                                    validation_split=0.2,\n",
        "                                                                    subset='training',\n",
        "                                                                    batch_size=None\n",
        "                                                                    )\n",
        "\n",
        "  dataset_validation=tf.keras.preprocessing.image_dataset_from_directory('/content/COMP530/'+directory_name,\n",
        "                                                                    labels='inferred',\n",
        "                                                                    label_mode='int',\n",
        "                                                                    class_names=['NormalCases','cancercases'],\n",
        "                                                                    image_size=(512,512),\n",
        "                                                                    shuffle=True,\n",
        "                                                                    seed=305,\n",
        "                                                                    validation_split=0.2,\n",
        "                                                                    subset='validation',\n",
        "                                                                    batch_size=None\n",
        "                                                                    )\n",
        "  \n",
        "  dataset_test=tf.keras.preprocessing.image_dataset_from_directory('/content/COMP530/'+directory_name,\n",
        "                                                                    labels='inferred',\n",
        "                                                                    label_mode='int',\n",
        "                                                                    class_names=['NormalCases','cancercases'],\n",
        "                                                                    image_size=(512,512),\n",
        "                                                                    shuffle=True,\n",
        "                                                                    seed=305,\n",
        "                                                                    validation_split=0.1,\n",
        "                                                                    subset='validation',\n",
        "                                                                    batch_size=None\n",
        "                                                                    )\n",
        "    \n",
        "  dataset_validation=dataset_validation.take(dataset_test.__len__())\n",
        "\n",
        "  return dataset_train,dataset_validation,dataset_test"
      ],
      "metadata": {
        "id": "0xqnACYcnK92"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ResNetPreprocess(image,label):\n",
        "  image = image/255.0\n",
        "  # Resize images from 512x512 to 224x224\n",
        "  image = tf.image.resize(image, (224,224))\n",
        "  return image, label"
      ],
      "metadata": {
        "id": "SSTkz2KVnLAu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE=32\n",
        "\n",
        "dataset_train,dataset_validation, dataset_test=Train_Validation_Test_Set(\"Dataset1\")\n",
        "dataset_train=dataset_train.map(ResNetPreprocess).batch(batch_size=BATCH_SIZE,drop_remainder=True)\n",
        "dataset_validation=dataset_validation.map(ResNetPreprocess).batch(batch_size=BATCH_SIZE,drop_remainder=True)\n",
        "dataset_test=dataset_test.map(ResNetPreprocess).batch(batch_size=BATCH_SIZE,drop_remainder=True)\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "dataset_train = dataset_train.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "dataset_validation = dataset_validation.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "sasC3SMInLDm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5cecc3d-9684-4a73-af7d-c1943fec94e8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1097 files belonging to 2 classes.\n",
            "Using 878 files for training.\n",
            "Found 1097 files belonging to 2 classes.\n",
            "Using 219 files for validation.\n",
            "Found 1097 files belonging to 2 classes.\n",
            "Using 109 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **mobilenet v2**"
      ],
      "metadata": {
        "id": "DIIXlp_N6oY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mobilenet_v2 = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
        "feature_extractor_model = mobilenet_v2\n",
        "\n",
        "feature_extractor_layer = hub.KerasLayer(\n",
        "    feature_extractor_model,\n",
        "    input_shape=(224, 224, 3),\n",
        "    trainable=False)\n",
        "\n",
        "num_classes = 1\n",
        "\n",
        "mobilenet = tf.keras.Sequential([\n",
        "  feature_extractor_layer,\n",
        "  tf.keras.layers.Dense(num_classes,activation='sigmoid')\n",
        "])\n",
        "\n",
        "mobilenet.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8uDHmpND7u5",
        "outputId": "c8cc539e-123b-4f31-fe82-178adb49ec08"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " keras_layer (KerasLayer)    (None, 1280)              2257984   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 1281      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,259,265\n",
            "Trainable params: 1,281\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mobilenet.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(),\n",
        "  loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "  metrics=[tf.keras.metrics.BinaryAccuracy(),tf.keras.metrics.TruePositives(),tf.keras.metrics.FalsePositives(),tf.keras.metrics.TrueNegatives(),tf.keras.metrics.FalseNegatives()])\n",
        "\n",
        "NUM_EPOCHS = 30\n",
        "\n",
        "history = mobilenet.fit(dataset_train,\n",
        "                    validation_data=dataset_validation,\n",
        "                    epochs=NUM_EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nayf5sJpGXpJ",
        "outputId": "34a50131-ae17-4291-80de-e7a73e0e38f4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "27/27 [==============================] - 4s 52ms/step - loss: 0.1773 - acc: 0.6215 - val_loss: 0.2545 - val_acc: 0.6042\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.1752 - acc: 0.6215 - val_loss: 0.2530 - val_acc: 0.6042\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.1732 - acc: 0.6215 - val_loss: 0.2516 - val_acc: 0.6042\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.1712 - acc: 0.6215 - val_loss: 0.2501 - val_acc: 0.6042\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.1693 - acc: 0.6215 - val_loss: 0.2487 - val_acc: 0.6042\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.1674 - acc: 0.6215 - val_loss: 0.2474 - val_acc: 0.6042\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.1656 - acc: 0.6215 - val_loss: 0.2460 - val_acc: 0.6042\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.1638 - acc: 0.6215 - val_loss: 0.2447 - val_acc: 0.6042\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.1621 - acc: 0.6215 - val_loss: 0.2434 - val_acc: 0.6042\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.1605 - acc: 0.6215 - val_loss: 0.2422 - val_acc: 0.6042\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 1s 31ms/step - loss: 0.1589 - acc: 0.6215 - val_loss: 0.2410 - val_acc: 0.6042\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.1573 - acc: 0.6215 - val_loss: 0.2398 - val_acc: 0.6042\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 1s 31ms/step - loss: 0.1558 - acc: 0.6215 - val_loss: 0.2386 - val_acc: 0.6042\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.1543 - acc: 0.6215 - val_loss: 0.2375 - val_acc: 0.6042\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.1528 - acc: 0.6215 - val_loss: 0.2364 - val_acc: 0.6042\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.1514 - acc: 0.6215 - val_loss: 0.2353 - val_acc: 0.6042\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.1500 - acc: 0.6215 - val_loss: 0.2342 - val_acc: 0.6042\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.1487 - acc: 0.6215 - val_loss: 0.2332 - val_acc: 0.6042\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.1473 - acc: 0.6215 - val_loss: 0.2321 - val_acc: 0.6042\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.1460 - acc: 0.6215 - val_loss: 0.2311 - val_acc: 0.6042\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.1448 - acc: 0.6215 - val_loss: 0.2301 - val_acc: 0.6042\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.1435 - acc: 0.6215 - val_loss: 0.2292 - val_acc: 0.6042\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1423 - acc: 0.6215 - val_loss: 0.2282 - val_acc: 0.6042\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.1412 - acc: 0.6215 - val_loss: 0.2273 - val_acc: 0.6042\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.1400 - acc: 0.6215 - val_loss: 0.2263 - val_acc: 0.6042\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.1389 - acc: 0.6215 - val_loss: 0.2254 - val_acc: 0.6042\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.1378 - acc: 0.6215 - val_loss: 0.2245 - val_acc: 0.6042\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.1367 - acc: 0.6215 - val_loss: 0.2237 - val_acc: 0.6042\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.1356 - acc: 0.6215 - val_loss: 0.2228 - val_acc: 0.6042\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.1346 - acc: 0.6215 - val_loss: 0.2220 - val_acc: 0.6042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history.history['binary_accuracy'])\n",
        "plt.plot(history.history['val_binary_accuracy'])\n",
        "plt.title('training accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('training loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "wznzxN5RLaQo",
        "outputId": "28610332-9aa7-4073-f913-c66578cd69c5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-d52d6319a46a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# summarize history for accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'acc'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Resnet 50**"
      ],
      "metadata": {
        "id": "Ducc8ja36SJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet = \"https://tfhub.dev/tensorflow/resnet_50/feature_vector/1\"\n",
        "feature_extractor_model = resnet\n",
        "\n",
        "feature_extractor_layer = hub.KerasLayer(\n",
        "    feature_extractor_model,\n",
        "    input_shape=(224, 224, 3),\n",
        "    trainable=False)\n",
        "\n",
        "num_classes = 1\n",
        "\n",
        "resnet50 = tf.keras.Sequential([\n",
        "  feature_extractor_layer,\n",
        "  tf.keras.layers.Dense(num_classes,activation='sigmoid')\n",
        "])\n",
        "\n",
        "resnet50.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxJ7eTCz3wbW",
        "outputId": "882e24d2-fcc1-4eda-dcc6-9751c3012dd7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " keras_layer_3 (KerasLayer)  (None, 2048)              23561152  \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 2049      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,563,201\n",
            "Trainable params: 2,049\n",
            "Non-trainable params: 23,561,152\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(),\n",
        "  loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "  metrics=[tf.keras.metrics.BinaryAccuracy(),tf.keras.metrics.TruePositives(),tf.keras.metrics.FalsePositives(),tf.keras.metrics.TrueNegatives(),tf.keras.metrics.FalseNegatives()])\n",
        "\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "history = resnet50.fit(dataset_train,\n",
        "                    validation_data=dataset_validation,\n",
        "                    epochs=NUM_EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tav2GYVI5lZ_",
        "outputId": "13fef03c-dfdd-4222-b83d-e0dd57d68665"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "27/27 [==============================] - 9s 105ms/step - loss: 0.4551 - binary_accuracy: 0.7650 - precision_1: 0.8047 - val_loss: 0.4348 - val_binary_accuracy: 0.8333 - val_precision_1: 0.8387\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 2s 68ms/step - loss: 0.3064 - binary_accuracy: 0.8773 - precision_1: 0.9168 - val_loss: 0.3896 - val_binary_accuracy: 0.8542 - val_precision_1: 0.8667\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 2s 66ms/step - loss: 0.2700 - binary_accuracy: 0.8900 - precision_1: 0.9438 - val_loss: 0.3471 - val_binary_accuracy: 0.8333 - val_precision_1: 0.8621\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 2s 66ms/step - loss: 0.2452 - binary_accuracy: 0.8981 - precision_1: 0.9517 - val_loss: 0.3243 - val_binary_accuracy: 0.8542 - val_precision_1: 0.8793\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 2s 66ms/step - loss: 0.2264 - binary_accuracy: 0.8970 - precision_1: 0.9534 - val_loss: 0.3080 - val_binary_accuracy: 0.8542 - val_precision_1: 0.8793\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 2s 67ms/step - loss: 0.2107 - binary_accuracy: 0.9097 - precision_1: 0.9636 - val_loss: 0.2946 - val_binary_accuracy: 0.8542 - val_precision_1: 0.8793\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 2s 73ms/step - loss: 0.1973 - binary_accuracy: 0.9132 - precision_1: 0.9657 - val_loss: 0.2834 - val_binary_accuracy: 0.8542 - val_precision_1: 0.8793\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 2s 69ms/step - loss: 0.1857 - binary_accuracy: 0.9259 - precision_1: 0.9721 - val_loss: 0.2738 - val_binary_accuracy: 0.8646 - val_precision_1: 0.8814\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 2s 66ms/step - loss: 0.1755 - binary_accuracy: 0.9375 - precision_1: 0.9726 - val_loss: 0.2653 - val_binary_accuracy: 0.8750 - val_precision_1: 0.8966\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 2s 66ms/step - loss: 0.1663 - binary_accuracy: 0.9444 - precision_1: 0.9766 - val_loss: 0.2578 - val_binary_accuracy: 0.8750 - val_precision_1: 0.8966\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history.history['binary_accuracy'])\n",
        "plt.plot(history.history['val_binary_accuracy'])\n",
        "plt.title('training accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('training loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6SyGrKsl7cBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50.evaluate(dataset_test)"
      ],
      "metadata": {
        "id": "ZUrHIr-3owd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mobilenet.evaluate(dataset_test)"
      ],
      "metadata": {
        "id": "0LFqZgM97O_d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}